{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c370c11f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:25:36.276903Z",
     "iopub.status.busy": "2025-10-11T19:25:36.276600Z",
     "iopub.status.idle": "2025-10-11T19:25:36.873432Z",
     "shell.execute_reply": "2025-10-11T19:25:36.873065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1 – Environment setup: load libraries, configure switches, grab API keys.\n",
    "import asyncio\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from threading import Thread\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import pandas as pd\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from groq import AsyncGroq\n",
    "\n",
    "# Optional imports: only required when you switch to the real production data flow.\n",
    "try:\n",
    "    from database import GCS_SQL_CONNECTION, connect_with_connector, database  # type: ignore\n",
    "    from ds.data_loading_utils import convert_to_json, optimize_json, query_user_data  # type: ignore\n",
    "except ImportError:\n",
    "    GCS_SQL_CONNECTION = None\n",
    "    connect_with_connector = None\n",
    "    database = None\n",
    "    convert_to_json = None\n",
    "    optimize_json = None\n",
    "    query_user_data = None\n",
    "\n",
    "# keep things simple by using the sample CSV first.\n",
    "DATA_SOURCE = \"sample\"  # Switch to \"actual\" only after wiring up database helpers.\n",
    "SAMPLE_DATA_PATH = \"user_features.csv\"  # Demo dataset bundled with the repo.\n",
    "OUTPUT_CSV_PATH = \"personalized_messages.csv\"  # Messages are appended here after every run.\n",
    "\n",
    "if DATA_SOURCE not in {\"sample\", \"actual\"}:\n",
    "    raise ValueError(\"DATA_SOURCE must be either 'sample' or 'actual'.\")\n",
    "\n",
    "OUTPUT_CSV_PATH = str(Path(OUTPUT_CSV_PATH))\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # Load secrets from .env (no-op if the file does not exist).\n",
    "\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")\n",
    "GROQ_MODEL_VERSION = \"llama-3.3-70b-versatile\"\n",
    "INTENT_TO_CONNECT = \"networking purposes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "891e6f55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:25:36.875337Z",
     "iopub.status.busy": "2025-10-11T19:25:36.875157Z",
     "iopub.status.idle": "2025-10-11T19:25:36.880245Z",
     "shell.execute_reply": "2025-10-11T19:25:36.879860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2 – Sample data helpers (used when DATA_SOURCE == \"sample\").\n",
    "def load_sample_profiles(path: str = SAMPLE_DATA_PATH) -> Tuple[int, List[int], Dict[int, Dict[str, object]]]:\n",
    "    \"\"\"Load six demo rows from the CSV and split them into requester + targets.\"\"\"\n",
    "    df = pd.read_csv(path).fillna(\"\")\n",
    "    if len(df) < 6:\n",
    "        raise ValueError(\"Sample dataset must contain at least 6 rows.\")\n",
    "\n",
    "    df[\"user_id\"] = df[\"user_id\"].astype(int)\n",
    "    primary_user_row = df.iloc[0]\n",
    "    target_rows = df.iloc[1:6]\n",
    "    primary_user_id = int(primary_user_row[\"user_id\"])\n",
    "    target_ids = [int(uid) for uid in target_rows[\"user_id\"].tolist()]\n",
    "\n",
    "    profile_map: Dict[int, Dict[str, object]] = {}\n",
    "    for _, row in df.iloc[:6].iterrows():\n",
    "        profile_map[int(row[\"user_id\"])] = row.to_dict()\n",
    "    return primary_user_id, target_ids, profile_map\n",
    "\n",
    "\n",
    "def prepare_sample_context() -> Tuple[int, str, List[int], Dict[int, Dict[str, object]]]:\n",
    "    \"\"\"Prepare the exact data structure the main pipeline expects in sample mode.\"\"\"\n",
    "    primary_user_id, sample_targets, profiles = load_sample_profiles()\n",
    "    for key, profile in profiles.items():\n",
    "        profile[\"USER_ID\"] = key\n",
    "    user_id = str(primary_user_id)\n",
    "    return primary_user_id, user_id, sample_targets, profiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a568b820",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:25:36.881830Z",
     "iopub.status.busy": "2025-10-11T19:25:36.881698Z",
     "iopub.status.idle": "2025-10-11T19:25:36.886926Z",
     "shell.execute_reply": "2025-10-11T19:25:36.886630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3 – Prompt templates and Groq helpers.\n",
    "PROMPT_NETWORKING = r\"\"\"\n",
    "You are a networking expert who can connect with anyone.\n",
    "Please compose a concise and compelling introductory message for me to reach out to a person on LinkedIn for {intent_to_connect}.\n",
    "Highlight our shared educational background, professional experiences, and mutual research interests to increase the likelihood of receiving a positive response.\n",
    "Only mention commonalities that are explicitly present in both profiles.\n",
    "If there is no clear shared background in education, work experience, or research interests, do not fabricate or assume any connections.\n",
    "Keep the message concise and to the point.\n",
    "\n",
    "User would give you two profiles: my_profile and target_profile.\n",
    "my_profile is the user's profile. target_profile is the profile for the user they want to connect.\n",
    "\n",
    "Please write a refined message that effectively communicates our shared background and interests to establish a meaningful connection for potential networking opportunities.\n",
    "Keep the message concise and simple, utilizing the best networking tips available in the world.\n",
    "Only mention commonalities that are explicitly present in both profiles.\n",
    "If there is no clear shared background, do not fabricate or assume any connections.\n",
    "Also, include a signoff note. Warm up the tone to make a more personal connection with the reader.\n",
    "Only return the messages and nothing else. Directly starts with message contents.\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_NETWORKING_NORUID = r\"\"\"\n",
    "You are a networking expert who can connect with anyone.\n",
    "Please compose a concise and compelling introductory message for me to reach out to a person on LinkedIn for {intent_to_connect}.\n",
    "Highlight ONLY the MAJOR educational background, professional experiences, OR research interests to increase the likelihood of receiving a positive response.\n",
    "Only mention things that are explicitly present in the profile.\n",
    "If there is no clear background in education, work experience, or research interests, do not fabricate or assume anything.\n",
    "Keep the message concise and to the point.\n",
    "\n",
    "User would give you one profile: target_profile.\n",
    "target_profile is the profile for the user they want to connect.\n",
    "\n",
    "Please write a refined message that effectively communicates major background and interests to establish a meaningful connection for potential networking opportunities.\n",
    "Keep the message concise and simple, utilizing the best networking tips available in the world.\n",
    "Only mention things that are explicitly present in the profile.\n",
    "If there is no clear background in education, work experience, or research interests, do not fabricate or assume anything.\n",
    "Also, include a signoff note. Warm up the tone to make a more personal connection with the reader.\n",
    "Only return the messages and nothing else. Directly starts with message contents.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_groq_client() -> AsyncGroq:\n",
    "    \"\"\"Create the Groq client after verifying that the API key is present.\"\"\"\n",
    "    if not GROQ_API_KEY:\n",
    "        raise EnvironmentError(\"GROQ_API_KEY is not set. Please configure your environment.\")\n",
    "    return AsyncGroq(api_key=GROQ_API_KEY)\n",
    "\n",
    "\n",
    "def build_prompt(no_ruid: bool, intent_to_connect: str, payload: Dict[str, object]) -> List[Dict[str, str]]:\n",
    "    \"\"\"Assemble the system + user messages the Groq chat endpoint expects.\"\"\"\n",
    "    if no_ruid:\n",
    "        system_prompt = PROMPT_NETWORKING_NORUID.format(intent_to_connect=intent_to_connect)\n",
    "    else:\n",
    "        system_prompt = PROMPT_NETWORKING.format(intent_to_connect=intent_to_connect)\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(payload, ensure_ascii=False)},\n",
    "    ]\n",
    "\n",
    "\n",
    "async def request_groq_completion(client: AsyncGroq, messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Send a chat completion request and return the plain-text answer.\"\"\"\n",
    "    response = await client.chat.completions.create(\n",
    "        messages=messages,\n",
    "        model=GROQ_MODEL_VERSION,\n",
    "        temperature=0,\n",
    "        seed=0,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "async def create_networking_message_groq(\n",
    "    client: AsyncGroq,\n",
    "    user_profile: Optional[Dict[str, object]],\n",
    "    target_profile: Dict[str, object],\n",
    "    no_ruid: bool,\n",
    "    intent_to_connect: str = INTENT_TO_CONNECT,\n",
    ") -> str:\n",
    "    \"\"\"Generate the personalized networking message for a single target profile.\"\"\"\n",
    "    if no_ruid:\n",
    "        payload = {\"target_profile\": target_profile}\n",
    "    else:\n",
    "        payload = {\"my_profile\": user_profile, \"target_profile\": target_profile}\n",
    "    messages = build_prompt(no_ruid=no_ruid, intent_to_connect=intent_to_connect, payload=payload)\n",
    "    return await request_groq_completion(client, messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc7915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:25:36.888401Z",
     "iopub.status.busy": "2025-10-11T19:25:36.888272Z",
     "iopub.status.idle": "2025-10-11T19:25:36.891638Z",
     "shell.execute_reply": "2025-10-11T19:25:36.891351Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4 – Convenience helper to store every generated message inside a CSV file.\n",
    "def save_messages_to_csv(\n",
    "    request_id: int,\n",
    "    ru_id: int,\n",
    "    user_id: str,\n",
    "    messages: Dict[int, str],\n",
    "    intent_to_connect: str,\n",
    "    output_path: str = OUTPUT_CSV_PATH,\n",
    ") -> None:\n",
    "    \"\"\"Append each generated message to a CSV file so non-technical users can read it.\"\"\"\n",
    "    rows = []\n",
    "    for target_id, message in messages.items():\n",
    "        rows.append(\n",
    "            {\n",
    "                \"request_id\": request_id,\n",
    "                \"ru_id\": ru_id,\n",
    "                \"user_id\": user_id,\n",
    "                \"target_user_id\": target_id,\n",
    "                \"intent_to_connect\": intent_to_connect,\n",
    "                \"message\": message,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    file_exists = Path(output_path).exists()\n",
    "    with open(output_path, mode=\"a\", encoding=\"utf-8\", newline=\"\") as csv_file:\n",
    "        writer = csv.DictWriter(\n",
    "            csv_file,\n",
    "            fieldnames=[\n",
    "                \"request_id\",\n",
    "                \"ru_id\",\n",
    "                \"user_id\",\n",
    "                \"target_user_id\",\n",
    "                \"intent_to_connect\",\n",
    "                \"message\",\n",
    "            ],\n",
    "        )\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abece8ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:25:36.893091Z",
     "iopub.status.busy": "2025-10-11T19:25:36.892963Z",
     "iopub.status.idle": "2025-10-11T19:25:36.900405Z",
     "shell.execute_reply": "2025-10-11T19:25:36.900036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5 – The main orchestration function used by both sample and real data flows.\n",
    "async def get_personalized_message(\n",
    "    request_id: int,\n",
    "    ru_id: Optional[int],\n",
    "    user_id: Optional[str],\n",
    "    target_user_list: Optional[List[int]],\n",
    "    conn=None,\n",
    "    intent_to_connect: str = INTENT_TO_CONNECT,\n",
    "    userPositions=None,\n",
    "    userEducations=None,\n",
    "    userData=None,\n",
    "    data_source: str = DATA_SOURCE,\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"Collect data, call Groq, and save the output messages to disk.\"\"\"\n",
    "    if data_source not in {\"sample\", \"actual\"}:\n",
    "        raise ValueError(\"data_source must be either 'sample' or 'actual'.\")\n",
    "\n",
    "    if data_source == \"sample\":\n",
    "        ru_id, user_id, target_user_list, user_dict = prepare_sample_context()\n",
    "        no_ruid = False\n",
    "        query_time = 0.0\n",
    "    else:\n",
    "        if query_user_data is None or convert_to_json is None or optimize_json is None:\n",
    "            raise ImportError(\n",
    "                \"Actual data mode requires database and data loading helpers to be installed.\"\n",
    "            )\n",
    "        if not target_user_list:\n",
    "            raise ValueError(\"target_user_list must be provided when DATA_SOURCE='actual'.\")\n",
    "        if user_id is None:\n",
    "            raise ValueError(\"user_id must be provided when DATA_SOURCE='actual'.\")\n",
    "\n",
    "        query_time_start = time.time()\n",
    "        try:\n",
    "            conn_internal = conn if conn else GCS_SQL_CONNECTION\n",
    "            all_users = target_user_list + [user_id]\n",
    "            user_data_result = await query_user_data(\n",
    "                conn_internal,\n",
    "                all_users,\n",
    "                userData=userData,\n",
    "                userPositions=userPositions,\n",
    "                userEducations=userEducations,\n",
    "            )\n",
    "            user_data, positions_data, education_data, no_ruid = user_data_result\n",
    "        except Exception as exc:\n",
    "            raise RuntimeError(f\"Failed to query user data: {exc}\") from exc\n",
    "\n",
    "        query_time_end = time.time()\n",
    "        query_time = query_time_end - query_time_start\n",
    "        user_dict = convert_to_json(user_data, positions_data, education_data)\n",
    "        user_dict = optimize_json(user_dict)\n",
    "        for key in user_dict.keys():\n",
    "            user_dict[key][\"USER_ID\"] = key\n",
    "\n",
    "    client = get_groq_client()\n",
    "    messages: Dict[int, str] = {}\n",
    "    message_gen_time_start = time.time()\n",
    "\n",
    "    for user in target_user_list:\n",
    "        try:\n",
    "            target_profile = user_dict.get(user)\n",
    "            if not target_profile:\n",
    "                messages[user] = \"\"\n",
    "                continue\n",
    "\n",
    "            base_profile = user_dict.get(ru_id) if ru_id is not None else None\n",
    "            if base_profile is None and user_id is not None:\n",
    "                try:\n",
    "                    fallback_id = int(user_id)\n",
    "                    base_profile = user_dict.get(fallback_id)\n",
    "                except ValueError:\n",
    "                    base_profile = None\n",
    "\n",
    "            use_no_ruid = no_ruid or base_profile is None\n",
    "            generated_message = await create_networking_message_groq(\n",
    "                client=client,\n",
    "                user_profile=base_profile,\n",
    "                target_profile=target_profile,\n",
    "                no_ruid=use_no_ruid,\n",
    "                intent_to_connect=intent_to_connect,\n",
    "            )\n",
    "            messages[user] = generated_message\n",
    "        except Exception as exc:\n",
    "            messages[user] = \"\"\n",
    "            print(f\"Error generating message for {user}: {exc}\")\n",
    "\n",
    "    message_gen_time_end = time.time()\n",
    "    message_gen_time = message_gen_time_end - message_gen_time_start\n",
    "\n",
    "    save_messages_to_csv(\n",
    "        request_id=request_id,\n",
    "        ru_id=ru_id if ru_id is not None else -1,\n",
    "        user_id=user_id if user_id is not None else \"sample-user\",\n",
    "        messages=messages,\n",
    "        intent_to_connect=intent_to_connect,\n",
    "    )\n",
    "\n",
    "    empty_message_count = sum(1 for msg in messages.values() if not msg)\n",
    "    status = \"SUCCESS\" if empty_message_count < len(target_user_list) else \"FAIL\"\n",
    "\n",
    "    return {\n",
    "        \"Request_ID\": request_id,\n",
    "        \"Messages\": messages,\n",
    "        \"Status\": status,\n",
    "        \"Query_Time\": query_time,\n",
    "        \"Message_Generation_Time\": message_gen_time,\n",
    "        \"Empty_Message_Count\": empty_message_count,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df5e99ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-11T19:25:36.902079Z",
     "iopub.status.busy": "2025-10-11T19:25:36.901957Z",
     "iopub.status.idle": "2025-10-11T19:26:49.772755Z",
     "shell.execute_reply": "2025-10-11T19:26:49.772159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Request_ID\": 123,\n",
      "  \"Messages\": {\n",
      "    \"1249886\": \"Hi, I came across your profile and noticed we're both based in New York City, which is a great hub for creative professionals like ourselves. I'm reaching out because I'd love to learn more about your experiences in the entertainment industry as a producer, and explore potential networking opportunities. Best regards,\",\n",
      "    \"1284328\": \"Hi, I came across your profile and noticed we're both based in New York City, which is a great starting point for a meaningful connection. I'd love to learn more about your experiences in the healthcare industry and explore potential networking opportunities. Looking forward to hearing from you and establishing a connection.\\n\\nBest regards,\",\n",
      "    \"1490244\": \"Hi, I came across your profile and noticed we're both based in New York City, which is a great hub for innovation and growth. I'm reaching out to expand my professional network and learn from like-minded individuals. I'd love to hear about your experiences as a research scientist at Meta and explore potential areas of collaboration. Looking forward to connecting and starting a conversation. Best regards,\",\n",
      "    \"1511359\": \"Hi, I came across your profile and noticed we're both based in New York City, which is a great hub for professionals in various fields. I'm reaching out because I'd love to expand my network and learn more about your experiences in Higher Education, particularly in research at Columbia University. With my background in Marketing & Advertising, I'm eager to explore potential synergies and learn from your expertise. Let's connect and see how we can support each other in our professional journeys. Best regards,\",\n",
      "    \"1610465\": \"Hi, I came across your profile and noticed we're both based in New York City, which is a great hub for innovation and professional growth. I'd love to connect and explore potential networking opportunities, especially given our shared experience working in Northern America and being part of the US professional network. Looking forward to hearing from you and potentially starting a meaningful connection.\\n\\nBest regards,\"\n",
      "  },\n",
      "  \"Status\": \"SUCCESS\",\n",
      "  \"Query_Time\": 0.0,\n",
      "  \"Message_Generation_Time\": 3.040152072906494,\n",
      "  \"Empty_Message_Count\": 0\n",
      "}\n",
      "Messages saved to personalized_messages.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/xdtdbgvd6lzclvr0gsrpt8vc0000gn/T/ipykernel_18646/1324971683.py:25: RuntimeWarning: coroutine '_run_sample_preview' was never awaited\n",
      "  sample_result = result_box[\"value\"]\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "# Step 6 – Quick smoke test for learners. Safe to rerun multiple times.\n",
    "if DATA_SOURCE == \"sample\":\n",
    "    async def _run_sample_preview():\n",
    "        return await get_personalized_message(\n",
    "            request_id=123,\n",
    "            ru_id=None,\n",
    "            user_id=None,\n",
    "            target_user_list=None,\n",
    "            intent_to_connect=INTENT_TO_CONNECT,\n",
    "            data_source=DATA_SOURCE,\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            sample_result = asyncio.run(_run_sample_preview())\n",
    "        except RuntimeError:\n",
    "            result_box: Dict[str, Dict[str, object]] = {}\n",
    "\n",
    "            def threaded_run():\n",
    "                result_box[\"value\"] = asyncio.run(_run_sample_preview())\n",
    "\n",
    "            worker = Thread(target=threaded_run, daemon=True)\n",
    "            worker.start()\n",
    "            worker.join()\n",
    "            sample_result = result_box[\"value\"]\n",
    "\n",
    "        print(json.dumps(sample_result, indent=2, ensure_ascii=False))\n",
    "        print(f\"Messages saved to {OUTPUT_CSV_PATH}.\")\n",
    "    except Exception as exc:\n",
    "        print(f\"Sample run failed: {exc}\")\n",
    "else:\n",
    "    print(\n",
    "        \"Switch DATA_SOURCE to 'actual' and rerun the notebook once the live data\"\n",
    "        \" dependencies are available.\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
